import { z } from 'zod';
import { zodToJsonSchema } from 'zod-to-json-schema';
import { PredictionServiceClient, helpers } from '@google-cloud/aiplatform'; // Assuming v1 namespace based on research
import { GCLOUD_PROJECT, GCLOUD_LOCATION, getVertexAIConfig } from '../config.js';
// Removed withRetries import
// Input Schema - Exported for use in index.ts
export const generateEmbeddingsInputSchema = z.object({
    texts: z.array(z.string()).min(1).max(250).describe("An array of text strings to generate embeddings for. Max 250 items per request."),
    // Add other parameters like autoTruncate or outputDimensionality if needed later
    // autoTruncate: z.boolean().optional().default(true).describe("Whether to automatically truncate input text if it exceeds the model's limit."),
    // outputDimensionality: z.number().int().positive().optional().describe("Optional desired output dimensionality (e.g., 768). Model default will be used if not specified.")
}).describe("Input for generating text embeddings using a Vertex AI model.");
// Output Schema
const embeddingSchema = z.object({
    statistics: z.object({
        token_count: z.number().int().positive().describe("Number of tokens in the input text."),
        truncated: z.boolean().describe("Whether the input text was truncated."),
    }).describe("Statistics about the embedding generation for a single input."),
    values: z.array(z.number()).describe("The embedding vector (array of numbers)."),
}).describe("A single text embedding result.");
const generateEmbeddingsOutputSchema = z.object({
    embeddings: z.array(embeddingSchema).describe("An array of embedding results, one for each input text string."),
}).describe("Output containing the generated text embeddings.");
// Define the handler function separately
async function generateEmbeddingsHandler(input) {
    const { embeddingModelId } = getVertexAIConfig(); // Removed unused retry config
    const { texts } = input;
    if (!GCLOUD_PROJECT || !GCLOUD_LOCATION) {
        throw new Error("Google Cloud project or location is not configured.");
    }
    // Initialize client - Adjust endpoint based on model/region requirements
    // Research suggested 'us-central1' might be necessary for experimental models
    const clientOptions = {
        apiEndpoint: `${GCLOUD_LOCATION}-aiplatform.googleapis.com`,
    };
    const predictionServiceClient = new PredictionServiceClient(clientOptions);
    const endpoint = `projects/${GCLOUD_PROJECT}/locations/${GCLOUD_LOCATION}/publishers/google/models/${embeddingModelId}`;
    // Prepare parameters (if any) - These seem constant per call for this tool
    const parameters = helpers.toValue({
    // autoTruncate: input.autoTruncate, // Example if added to input schema
    });
    try {
        // Process each text individually due to batch size constraint
        const embeddingResults = await Promise.all(texts.map(async (text) => {
            // Prepare instance for a single text
            const instance = {
                structValue: {
                    fields: {
                        content: { stringValue: text }
                    }
                }
            };
            const request = {
                endpoint: endpoint,
                instances: [instance], // Send only one instance
                parameters: parameters,
            };
            // predict returns a Promise resolving to an array: [response, request, options]
            const predictResponse = await predictionServiceClient.predict(request);
            const response = predictResponse[0]; // Get the actual response object
            if (!response.predictions || response.predictions.length !== 1) {
                // Expect exactly one prediction for one instance
                console.error("Unexpected number of predictions received:", response.predictions?.length);
                throw new Error(`Received ${response.predictions?.length ?? 0} predictions for a single input, expected 1.`);
            }
            const prediction = response.predictions[0];
            // Process the single prediction - Manually parse the IValue structure
            if (!prediction?.structValue?.fields?.embeddings?.structValue?.fields) {
                console.warn("Unexpected prediction structure:", JSON.stringify(prediction));
                throw new Error("Unexpected prediction structure received from Vertex AI.");
            }
            const embeddingFields = prediction.structValue.fields.embeddings.structValue.fields;
            // Extract statistics
            const statsField = embeddingFields.statistics?.structValue?.fields;
            if (statsField?.token_count?.numberValue === undefined || typeof statsField?.truncated?.boolValue !== 'boolean') {
                console.warn("Missing or invalid statistics fields:", JSON.stringify(statsField));
                throw new Error("Incomplete or invalid statistics data received.");
            }
            const statistics = {
                // Handle potential null value before rounding
                token_count: Math.round(statsField.token_count.numberValue ?? 0),
                truncated: statsField.truncated.boolValue,
            };
            // Extract values
            const valuesList = embeddingFields.values?.listValue?.values;
            if (!valuesList || !Array.isArray(valuesList)) {
                console.warn("Missing or invalid values list:", JSON.stringify(embeddingFields.values));
                throw new Error("Incomplete or invalid embedding values received.");
            }
            const values = valuesList.map(v => v.numberValue ?? 0); // Extract number value, default to 0 if null/undefined
            return {
                statistics: statistics,
                values: values,
            };
        })); // End of Promise.all map
        return { embeddings: embeddingResults };
    }
    catch (error) {
        console.error("Error calling Vertex AI Prediction API:", error);
        // Re-throw or handle specific errors as needed
        if (error instanceof Error) {
            throw new Error(`Vertex AI Prediction API Error: ${error.message}`);
        }
        throw new Error("An unknown error occurred during embedding generation.");
    }
}
// Export the tool definition conforming to the interface
export const generateEmbeddingsTool = {
    name: "generate_embeddings",
    description: "Generates text embeddings for a list of input strings using the configured Vertex AI embedding model (e.g., text-embedding-large-exp-03-07).",
    inputSchema: zodToJsonSchema(generateEmbeddingsInputSchema),
    // Output schema is needed for MCP, but the handler directly returns the structured data
    // outputSchema is not part of ToolDefinition
    // The 'handler' property is not part of the ToolDefinition interface.
    // The logic needs to be called directly from index.ts.
    // --> How are other tools that make direct API calls (like filesystem tools) integrated?
    // --> Let's check src/tools/index.ts and how tools are registered/used.
    // --> For now, let's comment out the handler and add a placeholder buildPrompt.
    // handler: generateEmbeddingsHandler,
    buildPrompt: (args, modelId) => {
        // This tool doesn't use a text prompt in the same way as LLM tools.
        // It makes a direct API call. We need to adapt the integration.
        // Returning dummy values for now.
        console.warn("generateEmbeddingsTool.buildPrompt is a placeholder and should not be directly used for LLM calls.");
        return {
            systemInstructionText: "",
            userQueryText: JSON.stringify(args), // Pass args for potential logging/debugging
            useWebSearch: false,
            enableFunctionCalling: false,
        };
    }
    // The handler function is exported separately below and needs to be called from index.ts
};
// Export the handler function itself for use in index.ts
export { generateEmbeddingsHandler };
